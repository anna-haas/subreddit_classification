{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...Description of what I am doing in this notebook....\n",
    "\n",
    "....\n",
    "\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About the API\n",
    "Reddit's API is fairly straightforward. For example, if I want the posts from /r/boardgames, all I have to do is add .json to the end of the url: https://www.reddit.com/r/boardgames.json\n",
    "\n",
    "TIPS:\n",
    "- Reddit will give you 25 posts per request. To get enough data, you'll need to hit Reddit's API repeatedly (most likely in a for loop). Be sure to use the time.sleep() function at the end of your loop to allow for a break in between requests. THIS IS CRUCIAL\n",
    "- The API will cap you at 1,000 posts for each subreddit (assuming the subreddit has that many posts).\n",
    "- At the end of each loop, be sure to save the results from your scrape as a csv: JSON from Reddit > Pandas DataFrame > CSV. That way, if something goes wrong in your loop, you won't lose all your data.\n",
    "\n",
    "To help you get started, we have a primer video on how to use Reddit's API: https://www.youtube.com/watch?v=5Y3ZE26Ciuk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import requests       \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Get Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets comments and information for all 1-3 level comments on a post (limit 25 per post)\n",
    "def get_comments(permalink):\n",
    "\n",
    "    # Get URL to comments page using permalink found in post information\n",
    "    url = 'https://www.reddit.com' + permalink + '.json'\n",
    "    headers = {'User-agent': 'swhaterBot 0.1'}\n",
    "    res = requests.get(url, headers=headers)\n",
    "    \n",
    "    # Verify status code is 200\n",
    "    if res.status_code == 200:\n",
    "        comments = res.json()\n",
    "    else:\n",
    "        return print('ERROR: ', res.status_code)\n",
    "    \n",
    "    # Creating dictionary to house all comments per post\n",
    "    all_comments = {}\n",
    "    # Creating lists to house comments by comment level (1, 2)\n",
    "    level1_coms = []\n",
    "    level2_coms = []\n",
    "    num_comments = 0\n",
    "    \n",
    "    #### LEVEL 1 ####\n",
    "    # Begin by getting top level comments\n",
    "    coms1_length = len(comments[1]['data']['children'])\n",
    "    \n",
    "    #print('# of Comments: ', coms1_length)\n",
    "    for i in range(coms1_length):\n",
    "        coms_sect1 = comments[1]['data']['children'][i]['data']\n",
    "        #print('Body in Keys: ', 'body' in coms_sect1.keys())\n",
    "        if 'body' in coms_sect1.keys():\n",
    "            top_level_com = coms_sect1['body']\n",
    "            level1_coms.append(top_level_com)\n",
    "            \n",
    "            if coms_sect1['replies'] != '':\n",
    "                \n",
    "                #### LEVEL 2 ####\n",
    "                coms2_length = len(coms_sect1['replies']['data']['children'])\n",
    "                \n",
    "                for j in range(coms2_length):\n",
    "                    coms_sect2 = coms_sect1['replies']['data']['children'][j]['data']\n",
    "                    if 'body' in coms_sect2.keys():\n",
    "                        sec_level_com = coms_sect2['body']\n",
    "                        level2_coms.append(sec_level_com)\n",
    "                \n",
    "        num_comments = len(level1_coms) + len(level2_coms) \n",
    "        #+ len(level3_coms)\n",
    "        \n",
    "        if num_comments > 30:\n",
    "            break\n",
    "        \n",
    "    all_comments['comts_first'] = level1_coms\n",
    "    all_comments['comts_second'] = level2_coms\n",
    "    all_comments['comts_num_collected'] = num_comments\n",
    "\n",
    "    return all_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets comments and information for all 1-2 level comments on a post (limit 30 per post)\n",
    "def get_comments_df(permalink):\n",
    "\n",
    "    # Get URL to comments page using permalink found in post information\n",
    "    url = 'https://www.reddit.com' + permalink + '.json'\n",
    "    headers = {'User-agent': 'swhaterBot 0.1'}\n",
    "    res = requests.get(url, headers=headers)\n",
    "    \n",
    "    # Verify status code is 200\n",
    "    if res.status_code == 200:\n",
    "        comments = res.json()\n",
    "    else:\n",
    "        return print('ERROR: ', res.status_code)\n",
    "    \n",
    "    # Creating list to house a dictionary for each row of comments\n",
    "    comments_list = []\n",
    "    counter = 0 # keep track of comments...max at 30 per post\n",
    "    \n",
    "    #### LEVEL 1 ####\n",
    "    coms1_length = len(comments[1]['data']['children'])\n",
    "    \n",
    "    #print('# of Comments: ', coms1_length)\n",
    "    for i in range(coms1_length):\n",
    "        comments_dict = {}\n",
    "        coms_sect1 = comments[1]['data']['children'][i]['data']\n",
    "   \n",
    "        if 'body' in coms_sect1.keys():\n",
    "            comments_dict['comment'] = coms_sect1['body'] # actual comment\n",
    "            comments_dict['level'] = 1\n",
    "            comments_dict['subreddit'] = permalink # permalink contains the subreddit name and can clean later\n",
    "            \n",
    "            comments_list.append(comments_dict)\n",
    "            counter += 1\n",
    "            \n",
    "            if coms_sect1['replies'] != '':\n",
    "                \n",
    "                #### LEVEL 2 ####\n",
    "                coms2_length = len(coms_sect1['replies']['data']['children'])\n",
    "                \n",
    "                for j in range(coms2_length):\n",
    "                    comments_dict = {}\n",
    "                    coms_sect2 = coms_sect1['replies']['data']['children'][j]['data']\n",
    "                    if 'body' in coms_sect2.keys():\n",
    "                        comments_dict['comment'] = coms_sect2['body'] # actual comment\n",
    "                        comments_dict['level'] = 2\n",
    "                        comments_dict['subreddit'] = permalink # permalink contains the subreddit name and can clean later\n",
    "\n",
    "                        comments_list.append(comments_dict)\n",
    "                        counter += 1\n",
    "                        \n",
    "        if counter> 30:\n",
    "            break\n",
    "\n",
    "    return  pd.DataFrame(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = '/r/SeriousConversation/comments/b8sgzc/person_from_my_graduating_class_died_the_other/'\n",
    "test1 = '/r/SeriousConversation/comments/b8t1zs/how_do_i_accept_the_fact_that_im_growing_up/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = pd.DataFrame()\n",
    "for permalink in [test, test1]:\n",
    "    df = get_comments_df(permalink)\n",
    "    comments_df = pd.concat([comments_df, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the indexx\n",
    "comments_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>level</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'd like to think he'd be happy you remembered...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b8sgzc/person_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I’d like to think so too.</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/SeriousConversation/comments/b8sgzc/person_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rest in peace stranger \\n\\nthank you for this ...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b8sgzc/person_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You’re welcome:)</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/SeriousConversation/comments/b8sgzc/person_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True. I think that's why people are often enco...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b8sgzc/person_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>From my strange stranger's pov, that's the way...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b8sgzc/person_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Something similar led me to think about life a...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b8sgzc/person_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I can relate to this. I just turned 24 and Ive...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b8sgzc/person_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I found out recently that an old co-worker of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b8sgzc/person_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I work at a high school and this year has been...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b8sgzc/person_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2 years ago someone I knew through elementary,...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b8sgzc/person_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Never stop being yourself, being grown up is b...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b8t1zs/how_do_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>You accept it, because it's happening and noth...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b8t1zs/how_do_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I appreciate the image. I believe I have an ik...</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/SeriousConversation/comments/b8t1zs/how_do_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>As a 30 something looking back wistfully of my...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b8t1zs/how_do_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>THAT makes sense. I like that way of viewing t...</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/SeriousConversation/comments/b8t1zs/how_do_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>It is really hard to move on and accept that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b8t1zs/how_do_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I do agree with the idea that growing changes ...</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/SeriousConversation/comments/b8t1zs/how_do_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>If I knew the exact answer I'd be living it my...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b8t1zs/how_do_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>That's true. The more you focus on things you ...</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/SeriousConversation/comments/b8t1zs/how_do_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22 yo here graduating this May. I've had these...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b8t1zs/how_do_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>There are so many huge goals I have for myself...</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/SeriousConversation/comments/b8t1zs/how_do_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>You're intelligent.  Increased intelligence ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b8t1zs/how_do_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>You'll age whether or not you accept it or not...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b8t1zs/how_do_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>You grow up.</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b8t1zs/how_do_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comment  level  \\\n",
       "0   I'd like to think he'd be happy you remembered...      1   \n",
       "1                          I’d like to think so too.       2   \n",
       "2   rest in peace stranger \\n\\nthank you for this ...      1   \n",
       "3                                   You’re welcome:)       2   \n",
       "4   True. I think that's why people are often enco...      1   \n",
       "5   From my strange stranger's pov, that's the way...      1   \n",
       "6   Something similar led me to think about life a...      1   \n",
       "7   I can relate to this. I just turned 24 and Ive...      1   \n",
       "8   I found out recently that an old co-worker of ...      1   \n",
       "9   I work at a high school and this year has been...      1   \n",
       "10  2 years ago someone I knew through elementary,...      1   \n",
       "11  Never stop being yourself, being grown up is b...      1   \n",
       "12  You accept it, because it's happening and noth...      1   \n",
       "13  I appreciate the image. I believe I have an ik...      2   \n",
       "14  As a 30 something looking back wistfully of my...      1   \n",
       "15  THAT makes sense. I like that way of viewing t...      2   \n",
       "16   It is really hard to move on and accept that ...      1   \n",
       "17  I do agree with the idea that growing changes ...      2   \n",
       "18  If I knew the exact answer I'd be living it my...      1   \n",
       "19  That's true. The more you focus on things you ...      2   \n",
       "20  22 yo here graduating this May. I've had these...      1   \n",
       "21  There are so many huge goals I have for myself...      2   \n",
       "22  You're intelligent.  Increased intelligence ca...      1   \n",
       "23  You'll age whether or not you accept it or not...      1   \n",
       "24                                       You grow up.      1   \n",
       "\n",
       "                                            subreddit  \n",
       "0   /r/SeriousConversation/comments/b8sgzc/person_...  \n",
       "1   /r/SeriousConversation/comments/b8sgzc/person_...  \n",
       "2   /r/SeriousConversation/comments/b8sgzc/person_...  \n",
       "3   /r/SeriousConversation/comments/b8sgzc/person_...  \n",
       "4   /r/SeriousConversation/comments/b8sgzc/person_...  \n",
       "5   /r/SeriousConversation/comments/b8sgzc/person_...  \n",
       "6   /r/SeriousConversation/comments/b8sgzc/person_...  \n",
       "7   /r/SeriousConversation/comments/b8sgzc/person_...  \n",
       "8   /r/SeriousConversation/comments/b8sgzc/person_...  \n",
       "9   /r/SeriousConversation/comments/b8sgzc/person_...  \n",
       "10  /r/SeriousConversation/comments/b8sgzc/person_...  \n",
       "11  /r/SeriousConversation/comments/b8t1zs/how_do_...  \n",
       "12  /r/SeriousConversation/comments/b8t1zs/how_do_...  \n",
       "13  /r/SeriousConversation/comments/b8t1zs/how_do_...  \n",
       "14  /r/SeriousConversation/comments/b8t1zs/how_do_...  \n",
       "15  /r/SeriousConversation/comments/b8t1zs/how_do_...  \n",
       "16  /r/SeriousConversation/comments/b8t1zs/how_do_...  \n",
       "17  /r/SeriousConversation/comments/b8t1zs/how_do_...  \n",
       "18  /r/SeriousConversation/comments/b8t1zs/how_do_...  \n",
       "19  /r/SeriousConversation/comments/b8t1zs/how_do_...  \n",
       "20  /r/SeriousConversation/comments/b8t1zs/how_do_...  \n",
       "21  /r/SeriousConversation/comments/b8t1zs/how_do_...  \n",
       "22  /r/SeriousConversation/comments/b8t1zs/how_do_...  \n",
       "23  /r/SeriousConversation/comments/b8t1zs/how_do_...  \n",
       "24  /r/SeriousConversation/comments/b8t1zs/how_do_...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get Posts using the comments function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts(subreddit):\n",
    "   \n",
    "    # Gathering Each Post from asubreddit\n",
    "    posts = []\n",
    "    after = True\n",
    "    for i in range(1,81):\n",
    "\n",
    "        if after == None: # if not enough posts will break the loop\n",
    "            break\n",
    "        else:\n",
    "            params = {'after': after}\n",
    "        \n",
    "        url = 'https://www.reddit.com/r/' + subreddit + '.json'\n",
    "        headers = {'User-agent': 'swhaterBot 0.1'}\n",
    "        res = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "        if res.status_code == 200:\n",
    "            the_json = res.json()\n",
    "            posts.extend(the_json['data']['children'])\n",
    "            after = the_json['data']['after']\n",
    "        else:\n",
    "            return print(res.status_code)\n",
    "\n",
    "        # keep status of how many posts collected\n",
    "        if i % 4 == 0:\n",
    "            print(f'{i*25} posts collected')\n",
    "\n",
    "        # sleep for 1 second\n",
    "        time.sleep(1)  \n",
    "        \n",
    "    # Veriry no duplicates\n",
    "    if len(posts) != len(set([p['data']['name'] for p in posts])):\n",
    "        print('Duplicate Present')\n",
    "    else:\n",
    "        print(f'FINAL: {len(posts)} posts collected')\n",
    "            \n",
    "        \n",
    "    posts_list = []\n",
    "    for  counter, post in enumerate(posts):\n",
    "    \n",
    "        single_post = {}\n",
    "        \n",
    "        # collect desired information from each post\n",
    "        single_post['title'] = post['data']['title']\n",
    "        single_post['selftext'] = post['data']['selftext']\n",
    "        single_post['permalink'] = post['data']['permalink']\n",
    "        single_post['subreddit'] = post['data']['subreddit']\n",
    "        single_post['author'] = post['data']['author']\n",
    "        single_post['url'] = post['data']['url']\n",
    "        single_post['name'] = post['data']['name']    \n",
    "        single_post['created'] = post['data']['created']\n",
    "        single_post['num_comments'] = post['data']['num_comments']\n",
    "        single_post['ups'] = post['data']['ups']\n",
    "        single_post['domain'] = post['data']['domain']\n",
    "        single_post['is_original_content'] = post['data']['is_original_content']\n",
    "        single_post['edited'] = post['data']['edited']\n",
    "        single_post['media_only'] = post['data']['media_only']\n",
    "        single_post['is_video'] = post['data']['is_video']\n",
    "\n",
    "        # Collect up to 25 comments if they exist (only first and second level)\n",
    "        if post['data']['num_comments'] != 0:\n",
    "            permalink = post['data']['permalink']\n",
    "            comments_dict = get_comments(permalink)\n",
    "            # Add comments dictionary for the post to the single_post dictionary\n",
    "            single_post.update(comments_dict)\n",
    "        else:\n",
    "            single_post['comts_first'] = []\n",
    "            single_post['comts_second'] = []\n",
    "            single_post['comts_num_collected'] = 0\n",
    "\n",
    "        posts_list.append(single_post) \n",
    "        \n",
    "        if counter % 100 == 0:\n",
    "            total_posts = len(posts)\n",
    "            pct_posts_collected = round((counter / total_posts) * 100, 2)\n",
    "            print(f'{pct_posts_collected}% posts with comments collected')\n",
    "\n",
    "    return pd.DataFrame(posts_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colllect & save data for r/CasualConversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 posts collected\n",
      "200 posts collected\n",
      "300 posts collected\n",
      "400 posts collected\n",
      "500 posts collected\n",
      "600 posts collected\n",
      "700 posts collected\n",
      "800 posts collected\n",
      "FINAL: 802 posts collected\n",
      "0.0% posts with comments collected\n",
      "12.47% posts with comments collected\n",
      "24.94% posts with comments collected\n",
      "37.41% posts with comments collected\n",
      "49.88% posts with comments collected\n",
      "62.34% posts with comments collected\n",
      "74.81% posts with comments collected\n",
      "87.28% posts with comments collected\n",
      "99.75% posts with comments collected\n"
     ]
    }
   ],
   "source": [
    "casual = get_posts('casualconversation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "casual.to_csv('../data/casual_coms.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colllect & save data for r/SeriousConversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 posts collected\n",
      "200 posts collected\n",
      "300 posts collected\n",
      "400 posts collected\n",
      "500 posts collected\n",
      "600 posts collected\n",
      "700 posts collected\n",
      "800 posts collected\n",
      "900 posts collected\n",
      "FINAL: 927 posts collected\n",
      "0.0% posts with comments collected\n",
      "10.79% posts with comments collected\n",
      "21.57% posts with comments collected\n",
      "32.36% posts with comments collected\n",
      "43.15% posts with comments collected\n",
      "53.94% posts with comments collected\n",
      "64.72% posts with comments collected\n",
      "75.51% posts with comments collected\n",
      "86.3% posts with comments collected\n",
      "97.09% posts with comments collected\n"
     ]
    }
   ],
   "source": [
    "serious = get_posts('../data/SeriousConversation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "serious.to_csv('../data/series_coms.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine & save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(802, 18)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(927, 18)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serious.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1729, 18)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([casual, serious], axis = 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = pd.concat([casual, serious], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to data folder\n",
    "conversations.to_csv('../data/conversations.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataframe for Only Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets comments and information for all 1-2 level comments on a post (limit 30 per post)\n",
    "def get_comments_df(subreddit):\n",
    "    \n",
    "    # Gathering Each Post from asubreddit\n",
    "    posts = []\n",
    "    all_comments_df = pd.DataFrame()\n",
    "    after = True\n",
    "    for i in range(1,81):\n",
    "\n",
    "        if after == None: # if not enough posts will break the loop\n",
    "            break\n",
    "        else:\n",
    "            params = {'after': after}\n",
    "        \n",
    "        url = 'https://www.reddit.com/r/' + subreddit + '.json'\n",
    "        headers = {'User-agent': 'swhaterBot 0.1'}\n",
    "        res = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "        if res.status_code == 200:\n",
    "            the_json = res.json()\n",
    "            posts.extend(the_json['data']['children'])\n",
    "            after = the_json['data']['after']\n",
    "        else:\n",
    "            return print(res.status_code)\n",
    "\n",
    "        # sleep for 1 second\n",
    "        time.sleep(1)  \n",
    "        \n",
    "    #posts_list = []\n",
    "    for  counter, post in enumerate(posts):\n",
    "\n",
    "        permalink = post['data']['permalink']\n",
    "        num_comments = post['data']['num_comments']\n",
    "        \n",
    "        if num_comments != 0:\n",
    "\n",
    "            # Get URL to comments page using permalink found in post information\n",
    "            url = 'https://www.reddit.com' + permalink + '.json'\n",
    "            headers = {'User-agent': 'swhaterBot 0.1'}\n",
    "            res = requests.get(url, headers=headers)\n",
    "\n",
    "            # Verify status code is 200\n",
    "            if res.status_code == 200:\n",
    "                comments = res.json()\n",
    "            else:\n",
    "                return print('ERROR: ', res.status_code)\n",
    "\n",
    "            # Creating list to house a dictionary for each row of comments\n",
    "            comments_list = []\n",
    "            num_comments = 0 # keep track of comments...max at 30 per post\n",
    "\n",
    "            #### LEVEL 1 ####\n",
    "            coms1_length = len(comments[1]['data']['children'])\n",
    "\n",
    "            #print('# of Comments: ', coms1_length)\n",
    "            for i in range(coms1_length):\n",
    "                comments_dict = {}\n",
    "                coms_sect1 = comments[1]['data']['children'][i]['data']\n",
    "\n",
    "                if 'body' in coms_sect1.keys():\n",
    "                    comments_dict['comment'] = coms_sect1['body'] # actual comment\n",
    "                    comments_dict['level'] = 1\n",
    "                    comments_dict['subreddit'] = permalink # permalink contains the subreddit name and can clean later\n",
    "\n",
    "                    comments_list.append(comments_dict)\n",
    "                    num_comments += 1\n",
    "\n",
    "                    if coms_sect1['replies'] != '':\n",
    "\n",
    "                        #### LEVEL 2 ####\n",
    "                        coms2_length = len(coms_sect1['replies']['data']['children'])\n",
    "\n",
    "                        for j in range(coms2_length):\n",
    "                            comments_dict = {}\n",
    "                            coms_sect2 = coms_sect1['replies']['data']['children'][j]['data']\n",
    "                            if 'body' in coms_sect2.keys():\n",
    "                                comments_dict['comment'] = coms_sect2['body'] # actual comment\n",
    "                                comments_dict['level'] = 2\n",
    "                                comments_dict['subreddit'] = permalink # permalink contains the subreddit name and can clean later\n",
    "\n",
    "                                comments_list.append(comments_dict)\n",
    "                                num_comments += 1\n",
    "\n",
    "                if num_comments > 30:\n",
    "                    break\n",
    "        \n",
    "        a_post_comments_df = pd.DataFrame(comments_list)\n",
    "        all_comments_df = pd.concat([all_comments_df, a_post_comments_df], axis=0)\n",
    "    \n",
    "    return all_comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "serious_coms = get_comments_df('SeriousConversation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "casual_coms = get_comments_df('CasualConversation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9596, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>level</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I wish it didn't overcrowd my feed</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/ayvt9u/looking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My 33yr old sister maced me(29yr old) last nig...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b7ysjq/megathr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm concocting an utterly evil prank, now all ...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b7ysjq/megathr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am coming to the sad realization that I will...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b7ysjq/megathr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Let's say you're having a discussion with an i...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/SeriousConversation/comments/b7ysjq/megathr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  level  \\\n",
       "0                 I wish it didn't overcrowd my feed      1   \n",
       "0  My 33yr old sister maced me(29yr old) last nig...      1   \n",
       "1  I'm concocting an utterly evil prank, now all ...      1   \n",
       "2  I am coming to the sad realization that I will...      1   \n",
       "3  Let's say you're having a discussion with an i...      1   \n",
       "\n",
       "                                           subreddit  \n",
       "0  /r/SeriousConversation/comments/ayvt9u/looking...  \n",
       "0  /r/SeriousConversation/comments/b7ysjq/megathr...  \n",
       "1  /r/SeriousConversation/comments/b7ysjq/megathr...  \n",
       "2  /r/SeriousConversation/comments/b7ysjq/megathr...  \n",
       "3  /r/SeriousConversation/comments/b7ysjq/megathr...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(serious_coms.shape)\n",
    "serious_coms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7885, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>level</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It helps if you make it a clickable link...\\n\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/CasualConversation/comments/ayvu98/looking_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It is clickable... it's a link post.</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/CasualConversation/comments/ayvu98/looking_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That sub should have a Reddit chat.</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/CasualConversation/comments/ayvu98/looking_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agree!</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/CasualConversation/comments/ayvu98/looking_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi, id be happy to talk to you :)</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/CasualConversation/comments/ayvu98/looking_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  level  \\\n",
       "0  It helps if you make it a clickable link...\\n\\...      1   \n",
       "1               It is clickable... it's a link post.      2   \n",
       "2               That sub should have a Reddit chat.       1   \n",
       "3                                             Agree!      2   \n",
       "4                  hi, id be happy to talk to you :)      1   \n",
       "\n",
       "                                           subreddit  \n",
       "0  /r/CasualConversation/comments/ayvu98/looking_...  \n",
       "1  /r/CasualConversation/comments/ayvu98/looking_...  \n",
       "2  /r/CasualConversation/comments/ayvu98/looking_...  \n",
       "3  /r/CasualConversation/comments/ayvu98/looking_...  \n",
       "4  /r/CasualConversation/comments/ayvu98/looking_...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(casual_coms.shape)\n",
    "casual_coms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17481, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = pd.concat([serious_coms, casual_coms], axis=0)\n",
    "comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to new csv data folder\n",
    "comments.to_csv('../data/comments.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
